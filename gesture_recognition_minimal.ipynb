{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ee33a87",
   "metadata": {},
   "source": [
    "# Hand Gesture Recognition - Minimal Version\n",
    "## Training model for 5 gesture classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95020832",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as 'TypeAliasType' could not be imported from 'c:\\Users\\PC-SON\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\typing_extensions.py'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import imageio\n",
    "import pickle\n",
    "\n",
    "# Deep Learning libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, Dropout, GRU, GlobalAveragePooling2D, \n",
    "    TimeDistributed\n",
    ")\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "\n",
    "# Suppress TensorFlow warnings (optional)\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "print(\"Libraries imported successfully\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "\n",
    "# Check GPU availability\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"GPU is available\")\n",
    "    print(f\"GPU devices: {tf.config.list_physical_devices('GPU')}\")\n",
    "else:\n",
    "    print(\"GPU not available, using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d29d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Setup paths and configuration\n",
    "import os\n",
    "\n",
    "    # Define project paths\n",
    "PROJECT_ROOT = os.path.abspath(os.getcwd())\n",
    "folder_name = os.path.join(PROJECT_ROOT, 'archive')\n",
    "folder_name = os.path.normpath(folder_name)\n",
    "\n",
    "# Path utility functions\n",
    "def resolve_sequence_dir(base_path, sequence_name):\n",
    "    \"\"\"Find correct sequence directory path\"\"\"\n",
    "    candidates = [\n",
    "        os.path.join(base_path, 'train', sequence_name),\n",
    "        os.path.join(base_path, 'train', 'train', sequence_name),\n",
    "        os.path.join(base_path, 'val', sequence_name),\n",
    "        os.path.join(base_path, 'val', 'val', sequence_name)\n",
    "    ]\n",
    "    \n",
    "    for path in candidates:\n",
    "        if os.path.exists(path) and os.path.isdir(path):\n",
    "            return path\n",
    "    return candidates[0]\n",
    "\n",
    "def list_sequence_frames(sequence_dir):\n",
    "    \"\"\"Get sorted list of image frames in sequence directory\"\"\"\n",
    "    if not os.path.exists(sequence_dir):\n",
    "        return []\n",
    "    return sorted([f for f in os.listdir(sequence_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
    "\n",
    "# Load CSV files\n",
    "train_csv = os.path.join(folder_name, 'train.csv')\n",
    "val_csv = os.path.join(folder_name, 'val.csv')\n",
    "\n",
    "train_doc = np.random.permutation(open(train_csv).readlines())\n",
    "val_doc = np.random.permutation(open(val_csv).readlines())\n",
    "\n",
    "# Configuration\n",
    "batch_size = 16  # Smaller batch size for better training\n",
    "x, y, z = 100, 100, 30  # Image dimensions and sequence length\n",
    "num_epochs = 20\n",
    "\n",
    "print(f\"Dataset path: {folder_name}\")\n",
    "print(f\"Training samples: {len(train_doc)}\")\n",
    "print(f\"Validation samples: {len(val_doc)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d97ea36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generator with MobileNet preprocessing\n",
    "def generator_mobilenet_gru(source_path, folder_list, batch_size, x, y, z, normalise, augment=False):\n",
    "    \"\"\"Generator for MobileNet + GRU model\"\"\"\n",
    "    print(f'Source path = {source_path}')\n",
    "    \n",
    "    while True:\n",
    "        t = np.random.permutation(folder_list)\n",
    "        \n",
    "        for i in range(0, len(t), batch_size):\n",
    "            batch_features = []\n",
    "            batch_labels = []\n",
    "            \n",
    "            for folder in t[i:i + batch_size]:\n",
    "                try:\n",
    "                    # Extract sequence name and label\n",
    "                    parts = folder.strip().split(';')\n",
    "                    sequence_name = parts[0]\n",
    "                    label = int(parts[2])\n",
    "                    \n",
    "                    # Get sequence directory\n",
    "                    sequence_dir = resolve_sequence_dir(source_path, sequence_name)\n",
    "                    imgs = list_sequence_frames(sequence_dir)\n",
    "                    \n",
    "                    if len(imgs) < z:\n",
    "                        continue\n",
    "                    \n",
    "                    # Sample frames uniformly\n",
    "                    source_frames = np.linspace(0, len(imgs) - 1, z).astype(int)\n",
    "                    \n",
    "                    batch_data = []\n",
    "                    for frame_idx in source_frames:\n",
    "                        image_path = os.path.join(sequence_dir, imgs[frame_idx])\n",
    "                        \n",
    "                        # Load and preprocess image\n",
    "                        image = imageio.imread(image_path)\n",
    "                        \n",
    "                        # Resize for MobileNet (224x224)\n",
    "                        image_resized = cv2.resize(image, (224, 224))\n",
    "                        \n",
    "                        # Normalize for MobileNet\n",
    "                        if normalise:\n",
    "                            image_normalized = tf.keras.applications.mobilenet_v2.preprocess_input(image_resized)\n",
    "                        else:\n",
    "                            image_normalized = image_resized / 255.0\n",
    "                            \n",
    "                        batch_data.append(image_normalized)\n",
    "                    \n",
    "                    batch_features.append(np.array(batch_data))\n",
    "                    \n",
    "                    # One-hot encode label (5 classes)\n",
    "                    one_hot = np.zeros(5)\n",
    "                    one_hot[label] = 1\n",
    "                    batch_labels.append(one_hot)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {folder}: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            if len(batch_features) > 0:\n",
    "                yield np.array(batch_features), np.array(batch_labels)\n",
    "\n",
    "print(\"Data generator defined successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d74d68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 8: Transfer Learning with MobileNet and GRU (Best performing model)\n",
    "def create_mobilenet_gru_model(sequence_length=30):\n",
    "    \"\"\"Create MobileNet + GRU model for gesture recognition\"\"\"\n",
    "    \n",
    "    # Load pre-trained MobileNetV2\n",
    "    base_model = MobileNetV2(input_shape=(224, 224, 3), \n",
    "                           include_top=False, \n",
    "                           weights='imagenet')\n",
    "    base_model.trainable = False  # Freeze base model\n",
    "    \n",
    "    # Create the full model\n",
    "    model = Sequential([\n",
    "        TimeDistributed(base_model, input_shape=(sequence_length, 224, 224, 3)),\n",
    "        TimeDistributed(GlobalAveragePooling2D()),\n",
    "        TimeDistributed(Dense(128, activation='relu')),\n",
    "        TimeDistributed(Dropout(0.5)),\n",
    "        \n",
    "        # GRU layers\n",
    "        GRU(64, return_sequences=True, dropout=0.5),\n",
    "        GRU(32, dropout=0.5),\n",
    "        \n",
    "        # Final classification layers\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(5, activation='softmax')  # 5 gesture classes\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create model\n",
    "model = create_mobilenet_gru_model(sequence_length=z)\n",
    "\n",
    "# Compile model\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['categorical_accuracy'])\n",
    "\n",
    "# Display model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b0b230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup callbacks (Fixed version)\n",
    "curr_dt_time = datetime.datetime.now()\n",
    "model_name = f'gesture_model_{curr_dt_time.strftime(\"%Y%m%d_%H%M%S\")}'\n",
    "\n",
    "if not os.path.exists(model_name):\n",
    "    os.makedirs(model_name)\n",
    "\n",
    "# Fixed callbacks - use .h5 format instead of .keras\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=os.path.join(model_name, 'best_model.h5'),  # Changed to .h5\n",
    "    monitor='val_categorical_accuracy',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    verbose=1,\n",
    "    mode='max'  # Added mode parameter\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=0.00001,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_categorical_accuracy',\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1,\n",
    "    mode='max'  # Added mode parameter\n",
    ")\n",
    "\n",
    "callbacks = [checkpoint, reduce_lr, early_stop]\n",
    "print(f\"Model will be saved to: {model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd547bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data generators\n",
    "train_generator = generator_mobilenet_gru(\n",
    "    folder_name, train_doc, batch_size, x, y, z, normalise=True, augment=True\n",
    ")\n",
    "\n",
    "val_generator = generator_mobilenet_gru(\n",
    "    folder_name, val_doc, batch_size, x, y, z, normalise=True, augment=False\n",
    ")\n",
    "\n",
    "# Calculate steps\n",
    "steps_per_epoch = len(train_doc) // batch_size\n",
    "validation_steps = len(val_doc) // batch_size\n",
    "\n",
    "print(f\"Steps per epoch: {steps_per_epoch}\")\n",
    "print(f\"Validation steps: {validation_steps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9209f90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "print(\"Starting training...\")\n",
    "print(f\"Training for {num_epochs} epochs with batch size {batch_size}\")\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bd79ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "def plot_training_history(history):\n",
    "    \"\"\"Plot training and validation metrics\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Plot accuracy\n",
    "    ax1.plot(history.history['categorical_accuracy'], label='Training Accuracy', color='blue')\n",
    "    ax1.plot(history.history['val_categorical_accuracy'], label='Validation Accuracy', color='red')\n",
    "    ax1.set_title('Model Accuracy')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # Plot loss\n",
    "    ax2.plot(history.history['loss'], label='Training Loss', color='blue')\n",
    "    ax2.plot(history.history['val_loss'], label='Validation Loss', color='red')\n",
    "    ax2.set_title('Model Loss')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print final results\n",
    "    final_train_acc = max(history.history['categorical_accuracy'])\n",
    "    final_val_acc = max(history.history['val_categorical_accuracy'])\n",
    "    \n",
    "    print(f\"\\n=== TRAINING RESULTS ===\")\n",
    "    print(f\"Best Training Accuracy: {final_train_acc:.4f} ({final_train_acc*100:.2f}%)\")\n",
    "    print(f\"Best Validation Accuracy: {final_val_acc:.4f} ({final_val_acc*100:.2f}%)\")\n",
    "    print(f\"Model saved to: {model_name}\")\n",
    "\n",
    "# Plot results\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38100000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final model (Fixed version)\n",
    "model.save(os.path.join(model_name, 'final_gesture_model.h5'))  # Changed to .h5\n",
    "print(f\"Final model saved to: {os.path.join(model_name, 'final_gesture_model.h5')}\")\n",
    "\n",
    "# Save training history\n",
    "import pickle\n",
    "with open(os.path.join(model_name, 'training_history.pkl'), 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "    \n",
    "print(\"Training complete! Your gesture recognition model is ready.\")\n",
    "print(\"\\n5 gesture classes supported:\")\n",
    "print(\"0: Thumbs Up\")\n",
    "print(\"1: Thumbs Down\") \n",
    "print(\"2: Left Swipe\")\n",
    "print(\"3: Right Swipe\")\n",
    "print(\"4: Stop Gesture\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
